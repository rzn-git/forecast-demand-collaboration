{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import h3\n",
    "from scipy.sparse import lil_matrix\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Debug Helper Function\n",
    "def debug(message, variable=None):\n",
    "    print(f\"[DEBUG] {message}\")\n",
    "    if variable is not None:\n",
    "        print(variable)\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('dataset/sales_4.csv')\n",
    "\n",
    "# Convert date column to datetime\n",
    "data['date'] = pd.to_datetime(data['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rznis\\AppData\\Local\\Temp\\ipykernel_24924\\2358809955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['week'] = filtered_data['date'].dt.to_period('W').apply(lambda r: r.start_time)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Node feature shape before GCN\n",
      "torch.Size([16, 100, 8])\n",
      "[DEBUG] Edge index shape\n",
      "torch.Size([2, 294])\n",
      "[DEBUG] Edge weight shape\n",
      "torch.Size([294])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select top N stores\n",
    "top_n = 100\n",
    "store_lifetime_product_count = data.groupby('store_id')['product_count'].sum()\n",
    "top_n_stores = store_lifetime_product_count.sort_values(ascending=False).head(top_n).index\n",
    "filtered_data = data[data['store_id'].isin(top_n_stores)]\n",
    "\n",
    "# Aggregate data to weekly demand per store\n",
    "filtered_data['week'] = filtered_data['date'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "weekly_data = filtered_data.groupby(['store_id', 'week']).agg({\n",
    "    'product_count': 'sum',\n",
    "    'latitude': 'first',\n",
    "    'longitude': 'first',\n",
    "    'locality_type': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Normalize demand and encode locality type\n",
    "weekly_data['product_count'] = (weekly_data['product_count'] - weekly_data['product_count'].mean()) / weekly_data['product_count'].std()\n",
    "locality_mapping = {'Diamond': 0, 'Gold': 1, 'Silver': 2}\n",
    "weekly_data['locality_type'] = weekly_data['locality_type'].map(locality_mapping)\n",
    "\n",
    "# Time-series pivot\n",
    "time_series = weekly_data.pivot(index='store_id', columns='week', values='product_count').fillna(0)\n",
    "\n",
    "# Create adjacency matrix using H3 indexing\n",
    "resolution = 3\n",
    "weekly_data['h3_index'] = weekly_data.apply(\n",
    "    lambda row: h3.latlng_to_cell(row['latitude'], row['longitude'], resolution), axis=1\n",
    ")\n",
    "h3_to_store_map = weekly_data.groupby('h3_index')['store_id'].apply(list).to_dict()\n",
    "h3_neighbors = {h: h3.grid_disk(h, 1) for h in h3_to_store_map.keys()}\n",
    "\n",
    "num_stores = len(weekly_data['store_id'].unique())\n",
    "adj_matrix = lil_matrix((num_stores, num_stores))\n",
    "store_to_idx = {store_id: idx for idx, store_id in enumerate(weekly_data['store_id'].unique())}\n",
    "\n",
    "for h3_index, neighbors in h3_neighbors.items():\n",
    "    stores_in_hex = h3_to_store_map.get(h3_index, [])\n",
    "    for neighbor in neighbors:\n",
    "        neighbor_stores = h3_to_store_map.get(neighbor, [])\n",
    "        for s1 in stores_in_hex:\n",
    "            for s2 in neighbor_stores:\n",
    "                idx1 = store_to_idx[s1]\n",
    "                idx2 = store_to_idx[s2]\n",
    "                adj_matrix[idx1, idx2] = 1\n",
    "\n",
    "adj_sparse = adj_matrix.tocsr()\n",
    "edge_index, edge_weight = from_scipy_sparse_matrix(adj_sparse)\n",
    "\n",
    "# Prepare node features\n",
    "locality_encoded = weekly_data.groupby('store_id')['locality_type'].first()\n",
    "locality_encoded = pd.get_dummies(locality_encoded, prefix='locality_type')\n",
    "locality_tensor = torch.tensor(locality_encoded.values, dtype=torch.float)\n",
    "node_features = torch.tensor(time_series.values, dtype=torch.float)\n",
    "node_features = torch.cat([node_features, locality_tensor], dim=1)\n",
    "\n",
    "debug(\"Node feature shape before GCN\", x.shape)\n",
    "debug(\"Edge index shape\", edge_index.shape)\n",
    "debug(\"Edge weight shape\", edge_weight.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Input shape to GCN\n",
      "torch.Size([16, 100, 8])\n",
      "[DEBUG] Shape after reshaping for GCN\n",
      "torch.Size([1600, 8])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1600x8 and 208x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 88\u001b[0m\n\u001b[0;32m     85\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Forward pass: input shape is (batch_size, num_nodes, time_steps)\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Output shape: (batch_size, forecast_steps)\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Reshape `y` to match `out` for loss calculation\u001b[39;00m\n\u001b[0;32m     91\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mview(out\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Ensure `y` has the same shape as `out`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[12], line 17\u001b[0m, in \u001b[0;36mSTGNN.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m     14\u001b[0m debug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape after reshaping for GCN\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Spatial convolution using GCNConv\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     19\u001b[0m debug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape after GCN\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:260\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m             edge_index \u001b[38;5;241m=\u001b[39m cache\n\u001b[1;32m--> 260\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m    263\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, edge_weight\u001b[38;5;241m=\u001b[39medge_weight)\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\dense\\linear.py:147\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1600x8 and 208x32)"
     ]
    }
   ],
   "source": [
    "class STGNN(nn.Module):\n",
    "    def __init__(self, in_channels, spatial_out, temporal_out, forecast_steps):\n",
    "        super(STGNN, self).__init__()\n",
    "        self.gcn = GCNConv(in_channels, spatial_out)\n",
    "        self.temporal_conv = nn.Conv1d(spatial_out, temporal_out, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(temporal_out, forecast_steps)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        batch_size, num_nodes, in_channels = x.shape\n",
    "        debug(\"Input shape to GCN\", x.shape)\n",
    "\n",
    "        # Reshape input for GCNConv to (batch_size * num_nodes, in_channels)\n",
    "        x = x.view(-1, in_channels)  # Flatten batch and nodes into one dimension\n",
    "        debug(\"Shape after reshaping for GCN\", x.shape)\n",
    "\n",
    "        # Spatial convolution using GCNConv\n",
    "        x = self.gcn(x, edge_index, edge_weight)\n",
    "        x = torch.relu(x)\n",
    "        debug(\"Shape after GCN\", x.shape)\n",
    "\n",
    "        # Reshape back to (batch_size, num_nodes, spatial_out)\n",
    "        x = x.view(batch_size, num_nodes, -1)  # Reshape after GCN to original batch and nodes\n",
    "        debug(\"Shape after reshaping for temporal conv\", x.shape)\n",
    "\n",
    "        # Temporal convolution (expecting shape: (batch_size, spatial_out, time_steps))\n",
    "        x = x.permute(0, 2, 1)  # Change shape to (batch_size, spatial_out, num_nodes) for Conv1d\n",
    "        debug(\"Shape before temporal convolution\", x.shape)\n",
    "\n",
    "        x = self.temporal_conv(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # Flatten and apply the final fully connected layer\n",
    "        x = x.mean(dim=-1)  # Take mean across the temporal dimension (num_nodes)\n",
    "        x = self.fc(x)\n",
    "        debug(\"Shape after fully connected layer\", x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Dataset Class\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, time_steps, forecast_steps):\n",
    "        self.data = data\n",
    "        self.time_steps = time_steps\n",
    "        self.forecast_steps = forecast_steps\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[1] - self.time_steps - self.forecast_steps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # x will have shape (num_nodes, time_steps)\n",
    "        x = self.data[:, idx:idx + self.time_steps]  # Select time steps\n",
    "        # y will have shape (num_nodes, forecast_steps)\n",
    "        y = self.data[:, idx + self.time_steps:idx + self.time_steps + self.forecast_steps]\n",
    "        return x.clone().detach(), y.clone().detach()\n",
    "\n",
    "# Training setup\n",
    "time_steps = 8\n",
    "forecast_steps = 1\n",
    "spatial_out = 32\n",
    "temporal_out = 64\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "\n",
    "dataset = TimeSeriesDataset(node_features, time_steps, forecast_steps)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = STGNN(\n",
    "    in_channels=node_features.shape[1],  # Match input feature dimension (e.g., 8)\n",
    "    spatial_out=spatial_out,\n",
    "    temporal_out=temporal_out,\n",
    "    forecast_steps=forecast_steps\n",
    ")\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: input shape is (batch_size, num_nodes, time_steps)\n",
    "        out = model(x, edge_index, edge_weight)  # Output shape: (batch_size, forecast_steps)\n",
    "\n",
    "        # Reshape `y` to match `out` for loss calculation\n",
    "        y = y.view(out.shape)  # Ensure `y` has the same shape as `out`\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(out, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(dataloader)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
